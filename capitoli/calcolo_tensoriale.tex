\cleardoublepage
\chapter{Calcolo tensoriale nella relatività generale}
\label{cha:calcolo-tensoriale}

\emph{Nota: da questo capitolo in poi ometteremo, per brevità, il prefisso
  \emph{quadri-} dove ciò non dovesse generare ambiguità.  Per esempio, useremo
  i termini \emph{tensore} e \emph{vettore} in luogo di, rispettivamente,
  \emph{quadritensore} e \emph{quadrivettore}.}

Nel paragrafo~\ref{sec:calcolo-tensoriale-minkowski} abbiamo introdotto, nel
contesto della relatività speciale, i tensori, specificando come si modificano
per effetto di una trasformazione di Lorentz, la quale è una trasformazione
lineare fra sistemi di riferimento inerziali.  Nella definizione dei tensori
intervengono le componenti $\tensor{\Lambda}{^{\alpha}_{\beta}}$ e
$\tensor{\Lambda}{_{\alpha}^{\beta}}$ delle matrici di Lorentz associate alle
specifiche trasformazioni considerate.

Anche nella relatività generale è utile introdurre i tensori, ma in questa
teoria si considerano trasformazioni arbitrarie, quindi non necessariamente
lineari, fra sistemi di riferimento anche non inerziali.  Abbiamo già notato
che, nella relatività speciale, gli elementi delle matrici delle trasformazioni
di Lorentz $x^{\alpha} \to x'^{\alpha}$ sono dati da
\begin{subequations}
  \begin{align}
    \tensor{\Lambda}{^{\alpha}_{\beta}} &= \parder{x'^{\alpha}}{x^{\beta}}, \\
    \tensor{\Lambda}{_{\beta}^{\alpha}} &= \parder{x^{\alpha}}{x'^{\beta}}.
  \end{align}
\end{subequations}
Definiremo i tensori, in relatività generale, in maniera analoga a quanto fatto
all'interno della relatività speciale, cioè prendendo come riferimento le
trasformazioni dei differenziali delle coordinate controvarianti che però adesso
non saranno le costanti $\tensor{\Lambda}{^{\alpha}_{\beta}}$ ma, in generale,
delle funzioni delle coordinate.  Rispetto al caso delle relatività speciale
bisognerà allora effettuare le sostituzioni
\begin{subequations}
  \label{eq:sostituzioni}
  \begin{align}
    \tensor{\Lambda}{^{\alpha}_{\beta}} &\to \parder{x'^{\alpha}}{x^{\beta}}, \\
    \tensor{\Lambda}{_{\beta}^{\alpha}} &\to \parder{x^{\alpha}}{x'^{\beta}}.
  \end{align}
\end{subequations}

Le uniche ipotesi che facciamo sulla trasformazione delle coordinate
$x^{\mu} \to x'^{\mu}$ è che sia rappresentata da una funzione biunivoca,
differenziabile (in modo che abbia senso calcolare la matrice jacobiana
$\lparder{x'^{\mu}}{x^{\mu}}$ della trasformazione), invertibile e con inverso a
sua volta differenziabile.  La trasformazione deve quindi avere determinante
jacobiano $\abs{\lparder{x'^{\mu}}{x^{\mu}}}$ non nullo, cioè non singolare, e
questo ci permetterà di definire anche nel presente contesto gli pseudotensori.

\section{Tensori}
\label{sec:tensori}

I differenziali delle coordinate controvarianti si trasformano, per effetto di
una trasformazione arbitraria delle coordinate $x^{\alpha} \to x'^{\alpha}$,
come
\begin{equation}
  \dd x'^{\alpha} = \parder{x'^{\alpha}}{x^{\mu}} \dd x^{\mu}.
\end{equation}
Un \emph{tensore}
$\tensor*{A}{^{\alpha_{1}\dots\alpha_{p}}_{\beta_{1}\dots\beta_{q}}}$ (con
$p + q = k$) di rango $k$ è un insieme di $4^{k}$ quantità che sotto una
trasformazione arbitraria delle coordinate $x^{\alpha} \to x'^{\alpha}$ si
trasformano come il differenziale delle coordinate controvarianti
\begin{equation}
  \tensor*{A}{^{\alpha_{1}\dots\alpha_{p}}_{\beta_{1}\dots\beta_{q}}} \to
  \tensor*{{A'}}{^{\alpha_{1}\dots\alpha_{p}}_{\beta_{1}\dots\beta_{q}}} =
  \parder{x'^{\alpha_{1}}}{x^{\mu_{1}}}
  \cdots \parder{x'^{\alpha_{p}}}{x^{\mu_{p}}} \parder{x^{\nu_{1}}}{x'^{\beta_{1}}}
  \cdots \parder{x^{\nu_{q}}}{x'^{\beta_{q}}}
  \tensor*{A}{^{\mu_{1}\dots\mu_{p}}_{\nu_{1}\dots\nu_{q}}}.
\end{equation}
Il tensore $\tensor*{A}{^{\alpha_{1}\dots\alpha_{p}}_{\beta_{1}\dots\beta_{q}}}$
è un tensore misto $p$ volte controvariante e $q$ volte covariante, oppure di
tipo $(p,q)$.  Un tensore di rango $k$ completamente controvariante è del tipo
$\tensor{A}{^{\alpha_{1}\dots\alpha_{k}}}$ e si trasforma come
\begin{equation}
  \tensor{A}{^{\alpha_{1}\dots\alpha_{k}}} \to
  \tensor{{A'}}{^{\alpha_{1}\dots\alpha_{k}}} =
  \parder{x'^{\alpha_{1}}}{x^{\mu_{1}}}
  \cdots \parder{x'^{\alpha_{k}}}{x^{\mu_{k}}}
  \tensor{A}{^{\mu_{1}\dots\mu_{k}}}.
\end{equation}
Un tensore di rango $k$ completamente covariante è del tipo
$\tensor{A}{_{\alpha_{1}\dots\alpha_{k}}}$ e si trasforma come
\begin{equation}
  \tensor{A}{_{\alpha_{1}\dots\alpha_{k}}} \to
  \tensor{{A'}}{_{\alpha_{1}\dots\alpha_{k}}} =
  \parder{x^{\mu_{1}}}{x'^{\alpha_{1}}}
  \cdots \parder{x^{\mu_{k}}}{x'^{\alpha_{k}}}
  \tensor{A}{_{\mu_{1}\dots\mu_{k}}}.
\end{equation}
In particolare, i tensori di rango $0$, che quindi non hanno indici, sono
chiamati \index{scalare}\emph{scalari} e sono invarianti sotto trasformazioni
arbitrarie di coordinate, i tensori di rango $1$ sono i \emph{vettori}.
Distinguiamo fra vettori controvarianti $V^{\alpha}$, i quali si trasformano,
per cambianti di coordinate $x^{\alpha} \to x'^{\alpha}$, come
\begin{equation}
  V^{\alpha} \to V'^{\alpha} = \parder{x'^{\alpha}}{x^{\mu}}V^{\mu},
\end{equation}
e vettori covarianti $U_{\alpha}$, che si trasformano come
\begin{equation}
  U_{\alpha} \to U'_{\alpha} = \parder{x^{\mu}}{x'^{\alpha}} U_{\mu}.
\end{equation}
Le trasformazioni inverse per i vettori controvarianti e covarianti sono
\begin{gather}
  V'^{\alpha} \to V^{\alpha} = \parder{x^{\alpha}}{x'^{\mu}} V'^{\mu}, \\
  U'_{\alpha} \to U_{\alpha} = \parder{x'^{\mu}}{x^{\alpha}} U'_{\mu}.
\end{gather}

Uno \index{pseudotensore}pseudotensore (o \emph{densità tensoriale})
$\tensor*{A}{^{\alpha_{1}\dots\alpha_{p}}_{\beta_{1}\dots\beta_{q}}}$ (con
$p+q=k$) di rango $k$ e peso $w$ è un insieme di $4^{k}$ quantità che per
effetto di un'arbitraria trasformazione delle coordinate
$x^{\alpha} \to x'^{\alpha}$ si trasformano come
\begin{equation}
  \tensor*{A}{^{\alpha_{1}\dots\alpha_{p}}_{\beta_{1}\dots\beta_{q}}} \to
  \tensor*{{A'}}{^{\alpha_{1}\dots\alpha_{p}}_{\beta_{1}\dots\beta_{q}}}
  = \abs*{\parder{x'}{x}}^{w} \parder{x'^{\alpha_{1}}}{x^{\mu_{1}}}
  \cdots \parder{x'^{\alpha_{p}}}{x^{\mu_{p}}} \parder{x^{\nu_{1}}}{x'^{\beta_{1}}}
  \cdots \parder{x^{\nu_{q}}}{x'^{\beta_{q}}}
  \tensor*{A}{^{\mu_{1}\dots\mu_{p}}_{\nu_{1}\dots\nu_{q}}},
\end{equation}
in cui $\abs{\lparder{x'}{x}}$ è lo jacobiano della trasformazione delle
coordinate.

La \index{delta!di Kronecker quadrimensionale}delta di Kronecker definita
nella~\eqref{eq:delta-kronecker} è l'unico tensore le cui componenti sono uguali
in qualsiasi sistema di riferimento, oltre agli \index{scalare}scalari e al
\index{tensore!nullo}tensore nullo.  Poiché anche nella relatività generale il
tensore nullo rimane invariato in ogni sistema di riferimento, è valido anche in
questo contesto il fatto che
\emph{se due tensori, dello stesso tipo, sono uguali in un sistema di
  riferimento, saranno uguali in qualsiasi sistema di riferimento ottenuto dal
  primo mediante una trasformazione arbitraria delle coordinate}.
Pertanto
\emph{una legge fisica espressa sotto forma di identità tensoriale è
  automaticamente generalmente covariante}.

Si noti che adesso le coordinate controvarianti non costituiscono più un
vettore.  Infatti, dopo una trasformazione generica, le nuove coordinate
$x'^{\alpha} = x'^{\alpha}(x)$ sono una funzione delle vecchie coordinate
$x^{\alpha} = x^{\alpha}(x')$.  Questa funzione è del tutto arbitraria in quanto
dipende dalla trasformazione, solo nel caso di trasformazioni lineari si ha
$x'^{\alpha} = \tensor{m}{^{\alpha}_{\beta}} x^{\beta}$, con
$\tensor{m}{^{\alpha}_{\beta}}$ matrice costante, e si può anche scrivere
\begin{equation}
  x'^{\alpha} = \parder{x'^{\alpha}}{x^{\beta}} x^{\beta}.
\end{equation}
Questo è proprio il caso delle trasformazioni di Lorentz.

\subsection{Tensore metrico}
\label{sec:tensore-metrico}

In un generico sistema di coordinate $x^{\mu}$, il
\index{tensore!metrico}tensore metrico è dato per definizione da
\begin{equation}
  g_{\mu\nu} =
  \eta_{\alpha\beta} \parder{\xi^{\alpha}}{x^{\mu}} \parder{\xi^{\beta}}{x^{\nu}},
\end{equation}
in cui $\xi^{\alpha}$ è un sistema di coordinate localmente inerziale.  In un
altro sistema di coordinate $x'^{\mu}$ risulta
\begin{equation}
  \label{eq:trasf-tensore-metrico}
  \begin{split}
    g'_{\mu\nu} &=
    \eta_{\alpha\beta} \parder{\xi^{\alpha}}{x'^{\mu}}
    \parder{\xi^{\beta}}{x'^{\nu}} =
    \eta_{\alpha\beta} \parder{\xi^{\alpha}}{x^{\rho}}
    \parder{x^{\rho}}{x'^{\mu}} \parder{\xi^{\beta}}{x^{\sigma}}
    \parder{x^{\sigma}}{x'^{\nu}} \\
    &= g_{\rho\sigma} \parder{x^{\rho}}{x'^{\mu}} \parder{x^{\sigma}}{x'^{\nu}}.
  \end{split}
\end{equation}
Dunque si tratta effettivamente di un tensore covariante di rango $2$.
Osserviamo che, a differenza del caso dello spazio di Minkowski piatto, nello
spazio-tempo curvo della relatività generale il \index{tensore!metrico}tensore
metrico $g_{\mu\nu}$ non è invariante per trasformazioni delle coordinate.  Nel
capitolo precedente abbiamo già introdotto il tensore metrico controvariante
$g^{\mu\nu}$ come quel tensore tale che
\begin{equation}
  g_{\mu\rho}g^{\mu\sigma} = \tensor{g}{^{\sigma}_{\rho}} =
  \tensor{\delta}{^{\sigma}_{\rho}}.
\end{equation}
Si dimostra che $g^{\mu\nu}$ è effettivamente un tensore controvariante di rango
$2$.

L'opposto del determinante della matrice che rappresenta il tensore metrico
\begin{equation}
  g = -\det(g_{\mu\nu})
\end{equation}
è uno pseudoscalare di peso $-2$.  Infatti, la
relazione~\eqref{eq:trasf-tensore-metrico} può essere scritta in forma
matriciale come
\begin{equation}
  g'_{\mu\nu} = \bigg( \parder{x}{x'}\bigg)^{\textup{T}} g_{\mu\nu}
  \bigg( \parder{x}{x'} \bigg),
\end{equation}
da cui, passando ai determinanti,
\begin{equation}
  \det(g'_{\mu\nu}) = \det(g_{\mu\nu}) \abs*{\parder{x}{x'}}^{2} \implies g' = g
  \abs*{\parder{x}{x'}}^{2} = g\abs*{\parder{x'}{x}}^{-2}.
\end{equation}
In particolare, considerando una trasformazione da un sistema di riferimento
inerziale, con $g_{\mu\nu} = \eta_{\mu\nu}$, a uno arbitrario abbiamo
\begin{equation}
  \det(g'_{\mu\nu}) = \det(\eta_{\mu\nu})\abs*{\parder{x}{x'}}^{2} = -
  \abs*{\parder{x}{x'}}^{2} < 0.
\end{equation}
Quindi si ha sempre $g > 0$ e ha senso considerare la sua radice quadrata
$\sqrt{g}$.  Poiché $g$ è uno pseudoscalare di peso $-2$, $\sqrt{g}$ è uno
pseudoscalare di peso $-1$
\begin{equation}
  \sqrt{g'} = \sqrt{g}\abs*{\parder{x'}{x}}^{-1}.
\end{equation}
Possiamo usare $\sqrt{g}$ per costruire un elemento infinitesimo di ipervolume
quadrimensionale invariante per arbitrarie trasformazione di coordinate.
Osserviamo che, come nella relatività
speciale,\footnote{Nella relatività speciale $\dd^{4} x$ può essere considerato
  uno scalare di Lorentz vero e proprio solo se ci si limita a considerare
  unicamente trasformazioni di Lorentz proprie, per le quali $\det \Lambda =
  1$.} $\dd^{4} x$ è uno pseudoscalare di peso $1$
\begin{equation}
  \dd^{4} x' = \dd^{4} x \abs*{\parder{x'}{x}}.
\end{equation}
Dunque l'elemento infinitesimo di ipersuperficie invariante è
$\sqrt{g}\dd^{4} x$
\begin{equation}
  \sqrt{g'}\dd^{4} x' = \sqrt{g}\abs*{\parder{x'}{x}}^{-1} \dd^{4} x
  \abs*{\parder{x'}{x}} = \sqrt{g}\dd^{4} x.
\end{equation}

Anche nella relatività generale il \index{tensore!metrico}tensore metrico può
essere usato per innalzare a abbassare gli indici dei tensori, per esempio
\begin{gather}
  V^{\alpha} \to V_{\alpha} = g_{\alpha\beta} V^{\beta}, \\
  U_{\alpha} \to U^{\alpha} = g^{\alpha\beta} U_{\beta}.
\end{gather}

\section{Operazioni con i tensori}
\label{sec:operazioni-tensori}

In questo paragrafo riporteremo le operazioni, già analizzate nel
paragrafo~\ref{sec:operazioni-tensori-minkowski}, che si possono effettuare con
i tensori anche all'interno della relatività generale.  Ometteremo le
dimostrazioni delle proprietà che sono state già svolte per lo spazio di
Minkowski poiché è sufficiente effettuare le
sostituzioni~\eqref{eq:sostituzioni} e usare il tensore metrico $g_{\mu\nu}$ al
posto del tensore di Minkowski $\eta_{\mu\nu}$.

\begin{description}
\item[Combinazione lineare] La combinazione lineare
  \begin{equation}
    a \tensor*{R}{^{\alpha_{1}\dots\alpha_{p}}_{\beta_{1}\dots\beta_{q}}} + b
    \tensor*{S}{^{\alpha_{1}\dots\alpha_{p}}_{\beta_{1}\dots\beta_{q}}},
  \end{equation}
  con $a$ e $b$ scalari, di due tensori dello stesso tipo è un tensore
  $\tensor*{T}{^{\alpha_{1}\dots\alpha_{p}}_{\beta_{1}\dots\beta_{q}}}$ ancora
  dello stesso tipo.
\item[Prodotto diretto] Il \index{prodotto!diretto}prodotto
  $\tensor*{A}{^{\alpha_{1}\dots\alpha_{p}}_{\beta_{1}\dots\beta_{q}}}
  \tensor*{B}{^{\alpha_{1}\dots\alpha_{r}}_{\beta_{1}\dots\beta_{s}}}$
  di un tensore di tipo $(p,q)$ e di uno di tipo $(r,s)$ è un tensore
  $\tensor*{T}{^{\alpha_{1}\dots\alpha_{p+r}}_{\beta_{1}\dots\beta_{q+s}}}$ di
  tipo $(p+r,q+s)$.
\item[Contrazione degli indici] \index{contrazione!degli indici}Se in un tensore
  di tipo $(p,q)$ si contraggono $n$ indici controvarianti con $n$ indici
  covarianti si ottiene un tensore di tipo $(p-n,q-n)$.  La contrazione di un
  tensore di rango superiore a $2$ non è univoca, si può scegliere di contrarre
  differenti coppie di indici ottenendo di volta in volta un risultato, in
  generale, diverso.  Ciascuna operazione di contrazione si effettua
  moltiplicando per il tensore metrico che ha per indici i due indici che si
  vogliono contrarre.  Due indici contratti possono essere scambiati di posto:
  l'indice covariante può diventare controvariante e, allo stesso tempo,
  l'indice controvariante diventare covariante, senza modificare il risultato.
  Non è invece possibile abbassare o alzare solo uno dei due indici muti.  Si
  può effettuare la contrazione degli indici anche nel prodotto di due tensori:
  il prodotto di un tensore di tipo $(p,q)$ e di uno di tipo $(r,s)$ è un
  tensore di tipo $(p+r,q+s)$, ma se si contraggono $n$ indici si ottiene un
  tensore di tipo $(p+r-n,q+s-n)$.
\item[Prodotto scalare] Il prodotto scalare fra due vettori $V$ e $U$ è definito
  come
  \begin{equation}
    V\cdot U = V^{\alpha}U_{\alpha} = g_{\alpha\beta}V^{\alpha}U^{\beta}.
  \end{equation}
  Il prodotto scalare di due vettori è un caso particolare di contrazione degli
  indici nel prodotto fra due tensori.  Dunque il loro prodotto è un tensore di
  rango $0$, cioè uno scalare e quindi una quantità che non varia per effetto di
  una trasformazione delle coordinate.
\end{description}

Non abbiamo ricordato fra le operazioni la derivazione poiché la derivazione
ordinaria nella relatività generale non ha le stesse importanti proprietà che
possiede nella relatività speciale.  Approfondiremo questo discorso nel
paragrafo~\ref{sec:derivazione-covariante}.

\section{Connessione affine}
\label{sec:connessione-affine}

Abbiamo definito la \index{connessione!affine}connessione affine come
\begin{equation}
  \tensor{\Gamma}{^{\lambda}_{\mu\nu}}
  = \parder{x^{\lambda}}{\xi^{\alpha}} \parder{\xi^{\alpha}}{x^{\mu},x^{\nu}},
\end{equation}
in cui $x^{\alpha}$ è un generico sistema di coordinate e
$\xi^{\alpha} = \xi^{\alpha}(x^{\alpha})$ un sistema localmente inerziale.
Considerando un altro sistema di coordinate $x'^{\mu} = x'^{\mu}(\xi^{\alpha})$
abbiamo
\begin{equation}
  \begin{split}
    \tensor{{\Gamma{}'}}{^{\lambda}_{\mu\nu}}
    &= \parder{x'^{\lambda}}{\xi^{\alpha}} \parder{}{x'^{\mu}}
    \bigg( \parder{\xi^{\alpha}(x)}{x'^{\nu}} \bigg)
    = \parder{x'^{\lambda}}{x^{\rho}} \parder{x^{\rho}}{\xi^{\alpha}}
    \parder{}{x'^{\mu}} \bigg( \parder{x^{\sigma}}{x'^{\nu}}
    \parder{\xi^{\alpha}}{x^{\sigma}} \bigg) \\
    &=  \parder{x'^{\lambda}}{x^{\rho}} \parder{x^{\rho}}{\xi^{\alpha}}
    \bigg( \parder{x^{\sigma}}{x'^{\nu}}
    \parder{\xi^{\alpha}}{x'^{\mu},x^{\sigma}} +
    \parder{x^{\sigma}}{x'^{\mu},x'^{\nu}} \parder{\xi^{\alpha}}{x^{\sigma}}
    \bigg) \\
    &= \parder{x'^{\lambda}}{x^{\rho}} \parder{x^{\rho}}{\xi^{\alpha}}
    \bigg( \parder{x^{\sigma}}{x'^{\nu}} \parder{x^{\tau}}{x'^{\mu}}
    \parder{\xi^{\alpha}}{x^{\tau},x^{\sigma}} +
    \parder{x^{\sigma}}{x'^{\mu},x'^{\nu}} \parder{\xi^{\alpha}}{x^{\sigma}}
    \bigg) \\
    &= \parder{x'^{\lambda}}{x^{\rho}} \parder{x^{\tau}}{x'^{\mu}}
    \parder{x^{\sigma}}{x'^{\nu}} \tensor{\Gamma}{^{\rho}_{\tau\sigma}}
    + \parder{x'^{\lambda}}{x^{\rho}} \parder{x^{\rho}}{x'^{\mu},x'^{\nu}}.
  \end{split}
\end{equation}
Questa relazione mostra che la connessione affine non è un tensore: se non ci
fosse il secondo termine nell'ultimo membro avremmo la formula di trasformazione
di un tensore di tipo $(1,2)$.

Riscriviamo il secondo termine dell'ultimo membro dell'equazione precedente in
una forma diversa che ci sarà utile in seguito.
% verrà usata nel paragrafo sulla derivazione covariante, *non* cancellare
% questo capoverso!
Derivando rispetto a $x'^{\mu}$
il primo e l'ultimo membro dell'identità
\begin{equation}
  \tensor{\delta}{^{\lambda}_{\nu}} = \parder{x'^{\lambda}}{x'^{\nu}}
  = \parder{x'^{\lambda}}{x^{\rho}} \parder{x^{\rho}}{x'^{\nu}}
\end{equation}
abbiamo
\begin{equation}
  0 = \parder{\tensor{\delta}{^{\lambda}_{\nu}}}{x'^{\mu}}
  = \parder{x'^{\lambda}}{x^{\rho}} \parder{x^{\rho}}{x'^{\mu}, x'^{\nu}}
  + \parder{x^{\rho}}{x'^{\nu}} \parder{x^{\sigma}}{x'^{\mu}}
  \parder{x'^{\lambda}}{x^{\rho},x^{\sigma}}.
\end{equation}
In questo modo la trasformazione della \index{connessione!affine}connessione
affine può essere riscritta come
\begin{equation}
  \tensor{{\Gamma{}'}}{^{\lambda}_{\mu\nu}}
  = \parder{x'^{\lambda}}{x^{\rho}} \parder{x^{\tau}}{x'^{\mu}}
  \parder{x^{\sigma}}{x'^{\nu}} \tensor{\Gamma}{^{\rho}_{\tau\sigma}}
  - \parder{x^{\rho}}{x'^{\nu}} \parder{x^{\sigma}}{x'^{\mu}}
  \parder{x'^{\lambda}}{x^{\rho},x^{\sigma}}.
\end{equation}

% La dimostrazione seguente è presa da Moshe Carmeli "Relativity: Modern
% Large-Scale Spacetime Structure of the Cosmos".  Vedi
% http://books.google.it/books?id=tZ2ilHyrkGUC&pg=PA110&lpg=PA110&dq=%22difference+between+two+affine+connections%22&source=bl&ots=Y1irJ0ao0z&sig=d2qZCZDSHPuD5-ykQM6C6hnXufQ&hl=it&sa=X&ei=Qn2mT87ALKzP4QTaluG_CQ&ved=0CE4Q6AEwAQ#v=onepage&q=%22difference%20between%20two%20affine%20connections%22&f=false
La connessione affine non è un tensore, ma la
\index{connessione!affine!differenza fra due connessioni affini}differenza fra
due connessioni affini è un tensore.  Infatti, siano
$\tensor{\Gamma}{^{\lambda}_{\mu\nu}}$ e
$\tensor{\tilde{\Gamma}}{^{\lambda}_{\mu\nu}}$ due distinte connessioni affini,
allora per un cambiamento di coordinate $x^{\mu} \to x'^{\mu}$ la loro
differenza
$\tensor{T}{^{\lambda}_{\mu\nu}} = \tensor{\Gamma}{^{\lambda}_{\mu\nu}} -
\tensor{\tilde{\Gamma}}{^{\lambda}_{\mu\nu}}$
si trasforma come un tensore di tipo $(1,2)$
\begin{equation}
  \begin{split}
    \tensor{T}{^{\lambda}_{\mu\nu}} \to \tensor{{T'}}{^{\lambda}_{\mu\nu}}
    &= \parder{x'^{\lambda}}{x^{\rho}} \parder{x^{\tau}}{x'^{\mu}}
    \parder{x^{\sigma}}{x'^{\nu}} \tensor{\Gamma}{^{\rho}_{\tau\sigma}}
    + \parder{x'^{\lambda}}{x^{\rho}} \parder{x^{\rho}}{x'^{\mu},x'^{\nu}} \\
    &- \parder{x'^{\lambda}}{x^{\rho}} \parder{x^{\tau}}{x'^{\mu}}
    \parder{x^{\sigma}}{x'^{\nu}} \tensor{\tilde{\Gamma}}{^{\rho}_{\tau\sigma}}
    - \parder{x'^{\lambda}}{x^{\rho}} \parder{x^{\rho}}{x'^{\mu},x'^{\nu}} \\
    &= \parder{x'^{\lambda}}{x^{\rho}} \parder{x^{\tau}}{x'^{\mu}}
    \parder{x^{\sigma}}{x'^{\nu}} \tensor{\Gamma}{^{\rho}_{\tau\sigma}}
    - \parder{x'^{\lambda}}{x^{\rho}} \parder{x^{\tau}}{x'^{\mu}}
    \parder{x^{\sigma}}{x'^{\nu}}\tensor{\tilde{\Gamma}}{^{\rho}_{\tau\sigma}}\\
    &= \parder{x'^{\lambda}}{x^{\rho}} \parder{x^{\tau}}{x'^{\mu}}
    \parder{x^{\sigma}}{x'^{\nu}} \tensor{T}{^{\rho}_{\tau\sigma}}.
  \end{split}
\end{equation}

\section{Derivazione covariante}
\label{sec:derivazione-covariante}

Nella relatività ristretta, la derivazione ordinaria di un tensore di rango $k$
rispetto a una coordinata $x^{\lambda}$ produce un tensore di rango $k+1$.
All'interno della teoria della relatività generale la situazione è differente:
la derivazione ordinaria di un tensore di rango $k$ per una coordinata
$x^{\lambda}$ produce un ente che non è, in generale, un tensore di rango $k+1$.
Per esempio, consideriamo un vettore controvariante $V^{\mu}$ il quale, per
definizione, si trasformerà, per effetto di un cambiamento di coordinate, come
\begin{equation}
  \label{eq:trasf-vettore}
  V^{\mu} \to V'^{\mu} = \parder{x'^{\mu}}{x^{\nu}} V^{\nu}.
\end{equation}
Derivando rispetto a $x'^{\lambda}$ abbiamo
\begin{equation}
  \begin{split}
    \parder{V'^{\mu}}{x'^{\lambda}}
    &= \parder{x'^{\mu}}{x^{\nu}} \parder{V^{\nu}}{x'^{\lambda}}
    + \parder{x'^{\mu}}{x'^{\lambda},x^{\nu}} V^{\nu} \\
    &= \parder{x'^{\mu}}{x^{\nu}} \parder{x^{\rho}}{x'^{\lambda}}
    \parder{V^{\nu}}{x^{\rho}}
    + \parder{x'^{\mu}}{x^{\nu},x^{\rho}} \parder{x^{\rho}}{x'^{\lambda}}
    V^{\nu}.
  \end{split}
\end{equation}
Se nell'ultimo membro ci fosse solo il primo termine avremmo che
$\lparder{V'^{\mu}}{x'^{\lambda}}$ sarebbe un tensore di rango $2$, tuttavia il
secondo termine è, in generale, diverso da zero.  Osserviamo che per
trasformazioni delle coordinate $x^{\mu} \to x'^{\mu}$ lineari, come le
trasformazioni di Lorentz, il secondo termine si annulla.

Vediamo come si trasforma per effetto di un cambiamento delle coordinate la
quantità $\tensor{\Gamma}{^{\mu}_{\nu\kappa}} V^{\kappa}$
\begin{equation}
  \begin{split}
    \tensor{{\Gamma{}'}}{^{\mu}_{\lambda\kappa}} V'^{\kappa} &=
    \bigg( \parder{x'^{\mu}}{x^{\nu}} \parder{x^{\sigma}}{x'^{\kappa}}
    \parder{x^{\rho}}{x'^{\lambda}} \tensor{\Gamma}{^{\nu}_{\rho\sigma}}
    -\parder{x^{\rho}}{x'^{\nu}} \parder{x^{\sigma}}{x'^{\kappa}}
    \parder{x'^{\mu}}{x^{\rho},x^{\sigma}} \bigg) \parder{x'^{\kappa}}{x^{\eta}}
    V^{\eta} \\
    &= \parder{x'^{\mu}}{x^{\nu}}
    \underbrace{\parder{x^{\sigma}}{x^{\eta}}}_{\tensor{\delta}{^{\sigma}_{\eta}}}
    \parder{x^{\rho}}{x'^{\lambda}} \tensor{\Gamma}{^{\nu}_{\rho\sigma}}
    V^{\eta} - \parder{x^{\rho}}{x'^{\nu}}
    \underbrace{\parder{x^{\sigma}}{x^{\eta}}}_{\tensor{\delta}{^{\sigma}_{\eta}}}
    \parder{x'^{\mu}}{x^{\rho},x^{\sigma}} V^{\eta} \\
    &= \parder{x'^{\mu}}{x^{\nu}} \parder{x^{\rho}}{x'^{\lambda}}
    \tensor{\Gamma}{^{\nu}_{\rho\sigma}} V^{\sigma}
    - \parder{x^{\rho}}{x'^{\nu}} \parder{x'^{\mu}}{x^{\rho},x^{\sigma}}
    V^{\sigma}.
  \end{split}
\end{equation}
Anche in questo caso, se nell'ultimo membro ci fosse solo il primo termine,
$\tensor{\Gamma}{^{\mu}_{\lambda\kappa}} V^{\kappa}$ si trasformerebbe come un
tensore misto di rango $2$, tuttavia il termine addizionale è opposto al termine
addizionale che compare nella trasformazione di
$\lparder{V^{\mu}}{x^{\lambda}}$, quindi la somma delle due quantità si
trasforma come un tensore misto di rango $2$, infatti
\begin{equation}
  \parder{V'^{\mu}}{x'^{\lambda}} + \tensor{{\Gamma{}'}}{^{\mu}_{\lambda\kappa}}
  V'^{\kappa} = \parder{x'^{\mu}}{x^{\nu}} \parder{x^{\rho}}{x'^{\lambda}}
  \bigg( \parder{V^{\nu}}{x^{\rho}} + \tensor{\Gamma}{^{\nu}_{\rho\sigma}}
  V'^{\sigma} \bigg).
\end{equation}
Definiamo allora la \index{derivata!covariante}\emph{derivata covariante}
$\tensor{V}{^{\mu}_{;\lambda}}$ di un vettore controvariante $V^{\mu}$ come
\begin{equation}
  \tensor{V}{^{\mu}_{;\lambda}} = \tensor{V}{^{\mu}_{,\lambda}} +
  \tensor{\Gamma}{^{\mu}_{\kappa\lambda}} V^{\kappa}
\end{equation}
e per un cambiamento delle coordinate $x^{\mu} \to x'^{\mu}$ si ha
\begin{equation}
  \tensor{V}{^{\mu}_{;\lambda}} \to \tensor{{V'}}{^{\mu}_{;\lambda}}
  = \parder{x'^{\mu}}{x^{\nu}} \parder{x^{\rho}}{x'^{\lambda}}
  \tensor{V}{^{\nu}_{;\rho}}
\end{equation}
cioè la derivata covariante di un vettore è un tensore di rango $2$, in analogia
alla derivazione ordinaria di un vettore nello spazio di Minkowski.

Ripetendo gli stessi calcoli per un vettore covariante si giunge a definire la
\index{derivata!covariante}derivata covariante $V_{\mu;\nu}$ di un vettore
covariante $V_{\mu}$ come
\begin{equation}
  V_{\mu;\nu} = V_{\mu,\nu} - \tensor{\Gamma}{^{\lambda}_{\mu\nu}} V_{\lambda}
\end{equation}
e per una trasformazione delle coordinate $x^{\mu} \to x'^{\mu}$ risulta
\begin{equation}
  V_{\mu;\nu} \to V'_{\mu;\nu}
  = \parder{x^{\lambda}}{x'^{\mu}} \parder{x^{\rho}}{x'^{\nu}} V_{\lambda;\rho}.
\end{equation}

Più in generale è possibile definire la \index{derivata!covariante}derivata
covariante di un tensore.  Vediamo il caso particolare di un tensore misto di
rango
tre\footnote{Presentiamo un metodo per ricordare la formula di derivazione
  covariante di un tensore di rango qualsiasi: il primo termine è la
  corrispondente derivazione ordinaria del tensore, i successivi sono del tipo
  $s\Gamma T$ cui $T$ ha, di volta in volta a rotazione, un solo indice muto e i
  restanti liberi, $\Gamma$ ha gli indici adeguati per saturare l'indice muto e
  compensare i due restanti indici liberi (di cui uno è sempre quello inferiore
  rispetto a cui si deriva, $\rho$ nell'esempio), $s$ vale $+1$ se l'indice muto
  di $T$ è controvariante, $-1$ se è covariante.}
\begin{subequations}
  \begin{align}
    \tensor{T}{^{\mu\sigma}_{\lambda;\rho}} &=
    \tensor{T}{^{\mu\sigma}_{\lambda,\rho}} + \tensor{\Gamma}{^{\mu}_{\rho\nu}}
    \tensor{T}{^{\nu\sigma}_{\lambda}} + \tensor{\Gamma}{^{\sigma}_{\rho\nu}}
    \tensor{T}{^{\mu\nu}_{\lambda}} - \tensor{\Gamma}{^{\nu}_{\rho\lambda}}
    \tensor{T}{^{\mu\sigma}_{\nu}}, \\
    \tensor{{T'}}{^{\mu\sigma}_{\lambda;\rho}}
    &= \parder{x'^{\mu}}{x^{\omega}} \parder{x'^{\sigma}}{x^{\tau}}
    \parder{x^{\alpha}}{x'^{\lambda}} \parder{x^{\beta}}{x'^{\rho}}
    \tensor{T}{^{\omega\tau}_{\alpha;\beta}}.
  \end{align}
\end{subequations}

Grazie alle proprietà algebriche dei tensori viste nel
paragrafo~\ref{sec:operazioni-tensori} si possono dimostrare le seguenti
proprietà della derivata covariante
\begin{enumerate}
\item la derivata covariante della combinazione lineare di tensori è uguale alla
  combinazione lineare delle derivate dei tensori
  \begin{equation}
    (\alpha \tensor*{A}{^{\mu_{1}\cdots\mu_{p}}_{\nu_{1}\cdots\nu_{q}}} + \beta
    \tensor*{B}{^{\mu_{1}\cdots\mu_{p}}_{\nu_{1}\cdots\nu_{q}}})_{;\lambda} =
    \alpha \tensor*{A}{^{\mu_{1}\cdots\mu_{p}}_{\nu_{1}\cdots\nu_{q};\lambda}} +
    \beta \tensor*{B}{^{\mu_{1}\cdots\mu_{p}}_{\nu_{1}\cdots\nu_{q};\lambda}},
  \end{equation}
  con $\alpha$ e $\beta$ scalari;
\item la derivata covariante del \index{prodotto!diretto}prodotto diretto di due
  tensori segue la \index{regola!di Leibniz}\emph{regola di Leibniz}
  \begin{equation}
    (\tensor*{A}{^{\mu_{1}\cdots\mu_{p}}_{\nu_{1}\cdots\nu_{q}}}
    \tensor*{B}{^{\mu_{1}\cdots\mu_{r}}_{\nu_{1}\cdots\nu_{s}}})_{;\lambda} =
    \tensor*{A}{^{\mu_{1}\cdots\mu_{p}}_{\nu_{1}\cdots\nu_{q};\lambda}}
    \tensor*{B}{^{\mu_{1}\cdots\mu_{r}}_{\nu_{1}\cdots\nu_{s}}} +
    \tensor*{A}{^{\mu_{1}\cdots\mu_{p}}_{\nu_{1}\cdots\nu_{q}}}
    \tensor*{B}{^{\mu_{1}\cdots\mu_{r}}_{\nu_{1}\cdots\nu_{s};\lambda}};
  \end{equation}
\item la derivata covariante della \index{contrazione!degli indici}contrazione
  di un tensore è uguale alla contrazione della derivata covariante del
  tensore.  Per esempio
  \begin{equation}
    \tensor{T}{^{\mu\lambda}_{\lambda;\rho}} =
    \tensor{T}{^{\mu\lambda}_{\lambda,\rho}} +
    \tensor{\Gamma}{^{\mu}_{\sigma\rho}}\tensor{T}{^{\sigma\lambda}_{\lambda}}.
  \end{equation}
  Infatti
  \begin{equation}
    \begin{split}
      \tensor{T}{^{\mu\lambda}_{\lambda;\rho}} &=
      \tensor{T}{^{\mu\lambda}_{\lambda,\rho}} +
      \tensor{\Gamma}{^{\mu}_{\sigma\rho}}\tensor{T}{^{\sigma\lambda}_{\lambda}}
      + \tensor{\Gamma}{^{\lambda}_{\sigma\rho}}
      \tensor{T}{^{\mu\sigma}_{\lambda}} -
      \tensor{\Gamma}{^{\sigma}_{\lambda\rho}}
      \tensor{T}{^{\mu\lambda}_{\sigma}} \\
      &= \tensor{T}{^{\mu\lambda}_{\lambda,\rho}} +
      \tensor{\Gamma}{^{\mu}_{\sigma\rho}}\tensor{T}{^{\sigma\lambda}_{\lambda}}
      + \tensor{\Gamma}{^{\sigma}_{\lambda\rho}}
      \tensor{T}{^{\mu\lambda}_{\sigma}} -
      \tensor{\Gamma}{^{\sigma}_{\lambda\rho}}
      \tensor{T}{^{\mu\lambda}_{\sigma}} \\
      &= \tensor{T}{^{\mu\lambda}_{\lambda,\rho}} +
      \tensor{\Gamma}{^{\mu}_{\sigma\rho}}\tensor{T}{^{\sigma\lambda}_{\lambda}}
    \end{split}
  \end{equation}
  in cui nel penultimo passaggio abbiamo scambiato gli indici muti $\lambda$ e
  $\sigma$ del terzo termine.
\end{enumerate}

La derivata covariante del \index{tensore!metrico}tensore metrico $g_{\mu\nu}$ è
nulla poiché in un sistema di coordinate localmente inerziale il tensore metrico
è uguale al \index{tensore!metrico di Minkowski}tensore di Minkowski
$\eta_{\mu\nu}$ e la derivata covariante del tensore di Minkowski è uguale al
tensore nullo.  Poiché il tensore nullo non cambia per trasformazioni arbitrarie
delle coordinate, la derivata covariante del tensore metrico è nulla in
qualsiasi sistema di coordinate.  Formalmente questo può essere fatto vedere
calcolando direttamente la derivata covariante di $g_{\mu\nu}$
\begin{equation}
  g_{\mu\nu;\lambda} = g_{\mu\nu,\lambda} -
  \tensor{\Gamma}{^{\rho}_{\lambda\mu}}g_{\rho\nu} -
  \tensor{\Gamma}{^{\rho}_{\lambda\nu}}g_{\rho\mu}
\end{equation}
e dalla~\eqref{eq:foo} abbiamo proprio $g_{\mu\nu;\lambda} = 0$.  Questo
risultato significa che l'operazione di abbassamento degli indici (o
innalzamento nel caso di $g^{\mu\nu}$) e derivazione covariante commutano, cioè
\begin{subequations}
  \begin{gather}
    (g_{\mu\nu}V^{\nu})_{;\lambda} = g_{\mu\nu;\lambda}V^{\nu} +
    g_{\mu\nu}\tensor{V}{^{\nu}_{;\lambda}} =
    g_{\mu\nu}\tensor{V}{^{\nu}_{;\lambda}}, \\
    (g^{\mu\nu}V_{\nu})_{;\lambda} = \tensor{g}{^{\mu\nu}_{;\lambda}}V_{\nu} +
    g^{\mu\nu}V_{\nu;\lambda} = g^{\mu\nu}V_{\nu;\lambda}.
  \end{gather}
\end{subequations}

La derivata covariante di uno scalare è uguale alla sua derivata ordinaria.
Infatti, sia $S$ uno scalare e $\tensor{V}{^{\mu}_{\nu}}$ un tensore tale che la
sua contrazione $\tensor{V}{^{\mu}_{\mu}}$ sia uguale a $S$, allora
\begin{equation}
  S_{;\lambda} = \tensor{V}{^{\mu}_{\mu;\lambda}} =
  \tensor{V}{^{\mu}_{\mu,\lambda}} + \tensor{\Gamma}{^{\mu}_{\sigma\lambda}}
  \tensor{V}{^{\sigma}_{\mu}} - \tensor{\Gamma}{^{\mu}_{\sigma\lambda}}
  \tensor{V}{^{\sigma}_{\mu}} = \tensor{V}{^{\mu}_{\mu,\lambda}} = S_{,\lambda}.
\end{equation}

Poiché la connessione affine è simmetrica rispetto ai suoi due indici inferiori,
il rotore covariante è uguale al rotore ordinario, infatti
\begin{equation}
  V_{\mu;\nu} - V_{\nu;\mu} = (V_{\mu,\nu} -
  \tensor{\Gamma}{^{\sigma}_{\mu\nu}}V_{\sigma}) - (V_{\nu,\mu} -
  \tensor{\Gamma}{^{\sigma}_{\nu\mu}} V_{\sigma}) = V_{\mu,\nu} - V_{\nu,\mu}.
\end{equation}

Calcoliamo la divergenza covariante $\tensor{V}{^{\mu}_{;\mu}}$ di un vettore
controvariante $V^{\mu}$
\begin{equation}
  \tensor{V}{^{\mu}_{;\mu}} = \tensor{V}{^{\mu}_{,\mu}} +
  \tensor{\Gamma}{^{\mu}_{\mu\lambda}} V^{\lambda}.
\end{equation}
Osserviamo che
\begin{equation}
  \tensor{\Gamma}{^{\mu}_{\mu\lambda}} =
  \frac{1}{2}(g^{\mu\rho}g_{\mu\rho,\lambda} + g^{\mu\rho}g_{\lambda\rho,\mu}
  - g^{\mu\rho}g_{\mu\lambda,\rho}) = \frac{1}{2}g^{\mu\rho}g_{\mu\rho,\lambda}.
\end{equation}
Inoltre si dimostrano le seguenti relazioni (vedi
l'appendice~\ref{sec:dimostr-determinante})
\begin{subequations}
  \label{eq:g_mu_rho-determinante}
  \begin{align}
    g^{\mu\rho} &= \frac{1}{g} \parder{g}{g_{\mu\rho}}, \\
    g_{\mu\rho} &= -
    \frac{1}{g} \parder{g}{g^{\mu\rho}}, \label{eq:g_mu_rho-determinante2}
  \end{align}
\end{subequations}
in cui $g = -\det(g_{\mu\nu})$, allora, usando in particolare la prima, possiamo
scrivere
\begin{equation}
  \tensor{\Gamma}{^{\mu}_{\mu\lambda}} = \frac{1}{2}
  \frac{1}{g} \parder{g}{g_{\mu\rho}} \parder{g_{\mu\rho}}{x^{\lambda}} =
  \frac{1}{2} \frac{1}{g} \parder{g}{x^{\lambda}} = \frac{1}{2} \parder{\ln
    g}{x^{\lambda}} = \parder{\ln \sqrt{g}}{x^{\lambda}} =
  \frac{1}{\sqrt{g}} \parder{\sqrt{g}}{x^{\lambda}}
\end{equation}
e quindi la divergenza covariante è
\begin{equation}
  \tensor{V}{^{\mu}_{;\mu}} = \parder{V^{\mu}}{x^{\mu}} +
  \tensor{\Gamma}{^{\mu}_{\mu\lambda}} V^{\lambda} = \parder{V^{\mu}}{x^{\mu}} +
  \frac{1}{\sqrt{g}} \parder{\sqrt{g}}{x^{\lambda}}V^{\lambda} =
  \frac{1}{\sqrt{g}} \parder{}{x^{\mu}}(\sqrt{g}V^{\mu}).
\end{equation}
Questo risultato ci permette di scrivere il \index{teorema!di Gauss}teorema di
Gauss in forma covariante, ricordando che l'elemento invariante infinitesimo di
volume quadrimensionale è $\sqrt{g}\dd^{4} x$,
\begin{equation}
  \label{eq:gauss-covariante}
  \int\limits_{\Omega} \tensor{V}{^{\mu}_{;\mu}} \sqrt{g} \dd^{4} x =
  \int\limits_{\Omega} \frac{1}{\sqrt{g}} \parder{}{x^{\mu}}(\sqrt{g}V^{\mu})
  \sqrt{g} \dd^{4} x = \int\limits_{\partial\Omega} V^{\mu} \sqrt{g}
  \dd\Sigma_{\mu}.
\end{equation}

\subsection{Differenziale covariante}
\label{sec:differenziale-covariante}

Abbiamo visto che la derivata ordinaria $\lparder{V^{\mu}}{x^{\lambda}}$ di un
vettore non è un tensore di rango $2$, in quanto il differenziale ordinario
$\dd V^{\mu}$ di un vettore $V^{\mu}$ non è un vettore, come invece succede
nello spazio piatto di Minkowski.  Infatti dalla~\eqref{eq:trasf-vettore}
abbiamo
\begin{equation}
  \dd V^{\mu} \to \dd V'^{\mu} = \parder{x'^{\mu}}{x^{\nu}} \dd V^{\nu}
  + \parder{x'^{\mu}}{x^{\nu},x^{\lambda}} V^{\nu} \dd x^{\lambda}
\end{equation}
e solo nel caso di trasformazioni lineari delle coordinate il secondo termine si
annulla e il differenziale si trasforma come un vettore.  Il motivo di ciò
risiede nel fatto che il differenziale di un vettore è dato dalla differenza dei
vettori $V^{\mu}(x + \dd x)$ e $V^{\mu}(x)$ valutati in due punti diversi dello
spazio e le leggi di trasformazione dei tensori in uno spazio curvo, come quello
della relatività generale, dipendono dalla posizione
\begin{equation}
  \begin{split}
    \dd V'^{\mu} &= V'^{\mu}(x' + \dd x') - V'^{\mu}(x') \\
    &= \bigg( \parder{x'^{\mu}}{x^{\nu}} \bigg) \bigg|_{x' + \dd x'}V^{\nu}(x +
    \dd x) - \bigg( \parder{x'^{\mu}}{x^{\nu}} \bigg) \bigg|_{x'} V^{\nu}(x).
  \end{split}
\end{equation}

Nasce allora l'esigenza di definire un differenziale di un vettore (o, più in
generale, di un tensore) che abbia a sua volta natura vettoriale (o tensoriale).
Per ovviare al problema della diversa posizione in cui vengono valutati i
vettori $V^{\mu}(x + \dd x)$ e $V^{\mu}(x)$ possiamo pensare di ``trasportare''
il vettore $V^{\mu}(x)$ dal punto $x$ al punto $x + \dd x$, mantenendo lo stesso
modulo e la stessa direzione rispetto alla curva $x^{\lambda}$.  In questo modo
si può introdurre il
\index{differenziale!covariante}\emph{differenziale covariante} $\cdd V^{\mu}$
di un vettore $V^{\mu}$ definito come la differenza fra il vettore
$V^{\mu}(x + \dd x)$ valutato nel punto $x + \dd x$ e il vettore $V^{\mu}(x)$
\emph{trasportato parallelamente} nel punto $x + \dd x$ (indichiamo con
$V^{*\mu}(x + \dd x)$ il vettore trasportato parallelamente)
\begin{equation}
  \begin{split}
    \cdd V^{\mu} &= V^{\mu}(x + \dd x) - V^{*\mu}(x + \dd x) = V^{\mu}(x + \dd x)
    - (V^{\mu}(x) + \delta V^{\mu}) \\
    &= \dd V^{\mu} - \delta V^{\mu},
  \end{split}
\end{equation}
in cui $\delta V^{\mu}$ è la variazione del vettore dovuta al suo
\index{trasporto!parallelo}\emph{trasporto parallelo} dal punto $x^{\lambda}$ al
punto $x^{\lambda} + \dd x^{\lambda}$.  Questa variazione deve essere nulla in
uno spazio piatto.

Definiamo $\delta V^{\mu}$ in modo che $\cdd V^{\mu}$ sia un vettore
controvariante.  Per fare questo consideriamo un sistema di coordinate inerziali
$x'^{\mu}$ e imponiamo che $\cdd V^{\mu}$ si trasformi, per effetto di un
cambiamento di coordinate $x^{\mu} \to x'^{\mu}$, come un vettore, cioè
\begin{equation}
  \cdd V^{\mu} \to \cdd V'^{\mu} = \parder{x'^{\mu}}{x^{\nu}} \cdd V^{\nu}
  = \parder{x'^{\mu}}{x^{\nu}} \dd V^{\nu} - \parder{x'^{\mu}}{x^{\nu}} \delta
  V^{\nu}.
\end{equation}
D'altra parte nel sistema di coordinate $x'^{\mu}$ abbiamo
$\cdd V'^{\mu} = \dd V'^{\mu} - \delta V'^{\mu}$, ma poiché questo sistema di
coordinate è piatto la variazione $\delta V'^{\mu}$ deve essere nulla, cioè il
differenziale covariante si deve trasformare come il differenziale ordinario
\begin{equation}
  \cdd V'^{\mu} = \dd V'^{\mu} = \parder{x'^{\mu}}{x^{\nu}} \dd V^{\nu}
  + \parder{x'^{\mu}}{x^{\rho},x^{\lambda}} V^{\rho} \dd x^{\lambda}
\end{equation}
quindi, per confronto ricaviamo
\begin{equation}
  - \parder{x'^{\mu}}{x^{\nu}} \delta V^{\nu}
  = \parder{x'^{\mu}}{x^{\rho},x^{\lambda}} V^{\rho} \dd x^{\lambda}
\end{equation}
da cui
\begin{equation}
  \delta V^{\nu} =
  - \parder{x'^{\mu}}{x^{\rho},x^{\lambda}} \parder{x^{\nu}}{x'^{\mu}} V^{\rho}
  \dd x^{\lambda}.
\end{equation}
Riconosciamo che il fattore di fronte a $V^{\rho} \dd x^{\lambda}$ è la
connessione affine $\tensor{\Gamma}{^{\nu}_{\rho\lambda}}$, quindi possiamo
definire il \index{differenziale!covariante}\emph{differenziale covariante} di
un vettore controvariante come
\begin{equation}
  \cdd V^{\mu} = \dd V^{\mu} + \tensor{\Gamma}{^{\mu}_{\rho\lambda}} V^{\rho} \dd
  x^{\lambda}.
\end{equation}
Osserviamo inoltre che risulta
\begin{equation}
  \cdd V^{\mu} = \parder{V^{\mu}}{x^{\lambda}} \dd x^{\lambda} +
  \tensor{\Gamma}{^{\mu}_{\rho\lambda}} V^{\rho} \dd x^{\lambda} =
  \tensor{V}{^{\mu}_{;\lambda}} \dd x^{\lambda}.
\end{equation}

Consideriamo una curva $x^{\lambda}(\tau)$ parametrizzata dal tempo proprio
$\tau$.  Uno spostamento infinitesimo lungo tale curva è dato da
$\dd x^{\lambda} = (\lparder{x^{\lambda}}{\tau}) \dd \tau = u^{\lambda}\dd\tau$,
quindi il differenziale covariante di $V^{\mu}$ si può scrivere come
\begin{equation}
  \cdd V^{\mu} = \dd V^{\mu} + \tensor{\Gamma}{^{\mu}_{\rho\lambda}} V^{\rho}
  u^{\lambda }\dd \tau.
\end{equation}
Allora il limite del rapporto incrementale $\cdd V^{\mu}/\dd \tau$ definisce la
\index{derivata!lungo una curva}\emph{derivata lungo la curva}
$x^{\lambda}(\tau)$ di $V^{\mu}$ come
\begin{equation}
  \curder{V^{\mu}} = \tensor{V}{^{\mu}_{;\lambda}} \toder{x^{\lambda}}{\tau} =
  \toder{V^{\mu}}{\tau} + \tensor{\Gamma}{^{\mu}_{\rho\lambda}} V^{\rho}
  \toder{x^{\lambda}}{\tau}.
\end{equation}
La derivata lungo una curva è un vettore in quanto è la contrazione fra il
tensore $\tensor{V}{^{\mu}_{;\lambda}}$ e la quadrivelocità
$\ltoder{x^{\lambda}}{\tau} = u^{\lambda}$.

Poiché $\delta V^{\mu} = 0$ in un sistema inerziale, in un tale sistema si deve
anche annullare la \index{connessione!affine}connessione affine.  Questo fa
vedere di nuovo che $\tensor{\Gamma}{^{\mu}_{\rho\lambda}}$ non può essere un
tensore: un tensore nullo in un sistema di coordinate è nullo in ogni altro
sistema di coordinate.

% TODO: scrivere questa sezione.  Lezione del 27/04/2012
\subsubsection{\completare{Esempio}}
\label{sec:esempio}

% TODO: scrivere questa sezione.  Lezione del 27/04/2012.  Vedi anche
% Ohanian-Ruffini, pagina 351.  Ricordati di sottolineare la differenza fra
% Lense-Thirring e De Sitter: De Sitter è dovuto alla sola presenza di una
% massa, Lense-Thirring è causato dalla rotazione della massa.
\subsection{\completare{Effetto De Sitter}}
\label{sec:effetto-de-sitter}

\section{Applicazioni del principio di generale covarianza}
\label{sec:applicazioni-generale-covarianza}

Grazie al formalismo introdotto in questo capitolo possiamo adottare l'algoritmo
che ci apprestiamo a esporre per determinare quale sia l'effetto della gravità
sui sistemi fisici: si scrive l'equazione che descrive il sistema, in assenza di
gravità, con il formalismo della relatività speciale e
\begin{itemize}
\item si sostituisce il \index{tensore!metrico}tensore metrico $g_{\mu\nu}$ al
  \index{tensore!metrico di Minkowski}tensore metrico di Minkowski
  $\eta_{\mu\nu}$;
\item si sostituiscono le \index{derivata!covariante}derivate covarianti alle
  derivate ordinarie e i \index{differenziale!covariante}differenziali
  covarianti ai differenziali ordinari;
\item si utilizzano opportune potenze di $\sqrt{g}$ per saturare a $0$ i pesi
  degli pseudotensori.
\end{itemize}
L'equazione così ottenuta sarà generalmente covariante e valida in assenza di
gravità e quindi, per il \index{principio!di generale covarianza}principio di
generale covarianza, sarà valida anche in presenza di campi gravitazionali.  È
possibile fare ciò a patto che si lavori su scale sufficientemente piccole
rispetto al raggio d'azione del campo gravitazionale.

Questo algoritmo ci permette, per esempio, di ricavare in maniera rapida
l'equazione del moto di una particella soggetta solo a un campo gravitazionale.
In assenza di gravità la particella è libera, quindi la sua equazione del moto è
\begin{equation}
  \toder{u^{\mu}}{\tau} = 0,
\end{equation}
in cui $u^{\mu}$ è la \index{quadrivelocità}quadrivelocità della particella.  In
presenza del campo gravitazionale, secondo le prescrizioni precedenti,
l'equazione del moto si scrive come
\begin{equation}
  0 = \curder{u^{\mu}} = \toder{u^{\mu}}{\tau} +
  \tensor{\Gamma}{^{\mu}_{\lambda\nu}} u^{\lambda} \toder{x^{\nu}}{\tau} =
  \toder{u^{\mu}}{\tau} + \tensor{\Gamma}{^{\mu}_{\lambda\nu}} u^{\lambda}
  u^{\nu},
\end{equation}
che è l'\index{equazione!della geodetica}equazione della
geodetica~\eqref{eq:geodetica2}.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../gravitazione"
%%% fill-column: 80
%%% TeX-PDF-mode: t
%%% End:
